{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GB107/newgpt/blob/main/OCTtoMCQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtERJQiTJ0tV",
        "outputId": "64b18e75-da4c-4735-cb47-7e4a80971846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clean-text[gpl]\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text[gpl])\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text[gpl])\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting unidecode<2.0.0,>=1.1.1 (from clean-text[gpl])\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text[gpl]) (0.2.13)\n",
            "Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=68dd4f41816222ffb83b18e7168f60836edfe23507d31c78b492df899f28fefc\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, unidecode, ftfy, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.2.0 unidecode-1.3.8\n",
            "Collecting python-doctr[torch]\n",
            "  Downloading python_doctr-0.8.1-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (8.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (1.26.4)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (1.13.1)\n",
            "Requirement already satisfied: h5py<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (3.11.0)\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (4.10.0.84)\n",
            "Collecting pypdfium2<5.0.0,>=4.0.0 (from python-doctr[torch])\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyclipper<2.0.0,>=1.2.0 (from python-doctr[torch])\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: shapely<3.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (2.0.5)\n",
            "Collecting langdetect<2.0.0,>=1.0.9 (from python-doctr[torch])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz<4.0.0,>=3.0.0 (from python-doctr[torch])\n",
            "  Downloading rapidfuzz-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (0.23.5)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (3.7.1)\n",
            "Collecting weasyprint>=55.0 (from python-doctr[torch])\n",
            "  Downloading weasyprint-62.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: Pillow>=9.2.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (9.4.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (0.7.1)\n",
            "Collecting mplcursors>=0.3 (from python-doctr[torch])\n",
            "  Downloading mplcursors-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: unidecode>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (1.3.8)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch<3.0.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr[torch]) (0.18.1+cu121)\n",
            "Collecting onnx<3.0.0,>=1.12.0 (from python-doctr[torch])\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect<2.0.0,>=1.0.9->python-doctr[torch]) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr[torch]) (2.8.2)\n",
            "Collecting matplotlib>=3.1.0 (from python-doctr[torch])\n",
            "  Downloading matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx<3.0.0,>=1.12.0->python-doctr[torch]) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=1.12.0->python-doctr[torch]) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=1.12.0->python-doctr[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=1.12.0->python-doctr[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=1.12.0->python-doctr[torch]) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=1.12.0->python-doctr[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pydyf>=0.10.0 (from weasyprint>=55.0->python-doctr[torch])\n",
            "  Downloading pydyf-0.11.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from weasyprint>=55.0->python-doctr[torch]) (1.16.0)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from weasyprint>=55.0->python-doctr[torch]) (1.1)\n",
            "Requirement already satisfied: tinycss2>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint>=55.0->python-doctr[torch]) (1.3.0)\n",
            "Collecting cssselect2>=0.1 (from weasyprint>=55.0->python-doctr[torch])\n",
            "  Downloading cssselect2-0.7.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting Pyphen>=0.9.1 (from weasyprint>=55.0->python-doctr[torch])\n",
            "  Downloading pyphen-0.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->python-doctr[torch]) (3.19.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->weasyprint>=55.0->python-doctr[torch]) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2>=0.1->weasyprint>=55.0->python-doctr[torch]) (0.5.1)\n",
            "Collecting zopfli>=0.1.4 (from fonttools[woff]>=4.0.0->weasyprint>=55.0->python-doctr[torch])\n",
            "  Downloading zopfli-0.2.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting brotli>=1.0.1 (from fonttools[woff]>=4.0.0->weasyprint>=55.0->python-doctr[torch])\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=1.12.0->python-doctr[torch]) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr[torch]) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=1.12.0->python-doctr[torch]) (1.3.0)\n",
            "Downloading matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading weasyprint-62.3-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m397.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_doctr-0.8.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
            "Downloading pydyf-0.11.0-py3-none-any.whl (8.1 kB)\n",
            "Downloading pyphen-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zopfli-0.2.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (848 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.9/848.9 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect, mplcursors\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=d426eee8555df1a2e1f84a3dc7dcb86dd64da9ead98122edb1065ad6b15cbaaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for mplcursors (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mplcursors: filename=mplcursors-0.5.3-py3-none-any.whl size=20727 sha256=0c8d3e2a96e62422d07c5b49971452a60c45d9ce52fbf1039a527b97a5d75a26\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/43/92/44f9515471f56877c774a515a2902d3e5484ea1bc7fd412d03\n",
            "Successfully built langdetect mplcursors\n",
            "Installing collected packages: pyclipper, brotli, zopfli, rapidfuzz, Pyphen, pypdfium2, pydyf, onnx, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, langdetect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, cssselect2, weasyprint, nvidia-cusolver-cu12, mplcursors, python-doctr\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "Successfully installed Pyphen-0.16.0 brotli-1.1.0 cssselect2-0.7.0 langdetect-1.0.9 matplotlib-3.9.0 mplcursors-0.5.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 onnx-1.16.2 pyclipper-1.3.0.post5 pydyf-0.11.0 pypdfium2-4.30.0 python-doctr-0.8.1 rapidfuzz-3.9.5 weasyprint-62.3 zopfli-0.2.3\n",
            "Collecting libretranslatepy\n",
            "  Downloading libretranslatepy-2.1.4-py3-none-any.whl.metadata (785 bytes)\n",
            "Downloading libretranslatepy-2.1.4-py3-none-any.whl (3.5 kB)\n",
            "Installing collected packages: libretranslatepy\n",
            "Successfully installed libretranslatepy-2.1.4\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement rapidfuzz==4.0.0 (from versions: 0.0.6, 0.0.7, 0.0.8, 0.1.0, 0.1.1, 0.2.0, 0.2.1, 0.2.2, 0.3.0, 0.4.0, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.6.0, 0.6.1, 0.6.2, 0.6.3, 0.6.4, 0.6.5, 0.6.6, 0.6.7, 0.6.8, 0.7.0, 0.7.1, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.7.7, 0.7.8, 0.7.9, 0.7.10, 0.7.11, 0.7.12, 0.8.0, 0.8.1, 0.8.2, 0.9.0, 0.9.1, 0.10.0, 0.11.0, 0.11.1, 0.11.2, 0.11.3, 0.12.0, 0.12.1, 0.12.2, 0.12.3, 0.12.4, 0.12.5, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.13.4, 0.14.0, 0.14.1, 0.14.2, 1.0.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.2.1, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.8.2, 1.8.3, 1.9.0, 1.9.1, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.0.10, 2.0.11, 2.0.12, 2.0.13, 2.0.14, 2.0.15, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0, 2.3.0, 2.4.1, 2.4.2, 2.4.3, 2.5.0, 2.6.0, 2.6.1, 2.7.0, 2.8.0, 2.9.0, 2.10.0, 2.10.1, 2.10.2, 2.10.3, 2.11.0, 2.11.1, 2.12.0, 2.13.0, 2.13.1, 2.13.2, 2.13.3, 2.13.4, 2.13.5, 2.13.6, 2.13.7, 2.14.0, 2.15.0, 2.15.1, 2.15.2, 3.0.0, 3.1.0, 3.1.1, 3.1.2, 3.2.0, 3.3.0, 3.3.1, 3.4.0, 3.5.1, 3.5.2, 3.6.0, 3.6.1, 3.6.2, 3.7.0, 3.8.0, 3.8.1, 3.9.0, 3.9.1, 3.9.2, 3.9.3, 3.9.4, 3.9.5)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for rapidfuzz==4.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.25)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.7.4)\n",
            "Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf2onnx\n",
            "Successfully installed tf2onnx-1.16.1\n",
            "Collecting replicate\n",
            "  Downloading replicate-0.31.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.1)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.20.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.2)\n",
            "Downloading replicate-0.31.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 replicate-0.31.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n",
            "Collecting flask_cors\n",
            "  Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask_cors) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.9->flask_cors) (2.1.5)\n",
            "Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n",
            "Installing collected packages: flask_cors\n",
            "Successfully installed flask_cors-4.0.1\n",
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask_ngrok) (2.1.5)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask_ngrok\n",
            "Successfully installed flask_ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install clean-text[gpl]\n",
        "!pip install python-doctr[torch]\n",
        "!pip install libretranslatepy\n",
        "!pip install natsort\n",
        "!pip install nltk\n",
        "!pip install pyspellchecker\n",
        "!pip install tqdm\n",
        "!pip install rapidfuzz==4.0.0\n",
        "!pip install torch\n",
        "!pip install tf2onnx\n",
        "!pip install replicate\n",
        "!pip install pyngrok\n",
        "!pip install flask_cors\n",
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install flask_ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wl75t7nNBAWf"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "import contextlib\n",
        "import os\n",
        "import pprint as pp\n",
        "import nltk\n",
        "import re\n",
        "import shutil\n",
        "import time\n",
        "import torch\n",
        "from datetime import date, datetime\n",
        "from os.path import basename, dirname, join\n",
        "from pathlib import Path\n",
        "\n",
        "from cleantext import clean\n",
        "from doctr.io import DocumentFile\n",
        "from doctr.models import ocr_predictor\n",
        "from libretranslatepy import LibreTranslateAPI\n",
        "from natsort import natsorted\n",
        "from spellchecker import SpellChecker\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import pyngrok\n",
        "\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_SrCAl9wvPgfAfBx9sP0uOospTS4pZaL09tThv\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW-2uetgi5it",
        "outputId": "0b124957-e538-4d36-a3d2-a32d37bfcce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\n",
            "··········\n",
            " * ngrok tunnel available, access with `ssh root@0.tcp.ngrok.io -p15782`\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "# Open a TCP ngrok tunnel to the SSH server\n",
        "connection_string = ngrok.connect(22, \"tcp\").public_url\n",
        "\n",
        "ssh_url, port = connection_string.strip(\"tcp://\").split(\":\")\n",
        "print(f\" * ngrok tunnel available, access with `ssh root@{ssh_url} -p{port}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GgcfFfYBEEC_"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-⁶\n",
        "\"\"\n",
        "\n",
        "# easyocr.py - A wrapper for easyocr to convert pdf to images to text\n",
        "\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %I:%M:%S\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def simple_rename(filepath, target_ext=\".txt\"):\n",
        "    _fp = Path(filepath)\n",
        "    basename = _fp.stem\n",
        "    return f\"OCR_{basename}_{target_ext}\"\n",
        "\n",
        "\n",
        "def rm_local_text_files(name_contains=\"RESULT_\"):\n",
        "    \"\"\"\n",
        "    rm_local_text_files - remove local text files\n",
        "\n",
        "    Args:\n",
        "        name_contains (str, optional): [description]. Defaults to \"OCR_\".\n",
        "    \"\"\"\n",
        "    files = [\n",
        "        f\n",
        "        for f in Path.cwd().iterdir()\n",
        "        if f.is_file() and f.suffix == \".txt\" and name_contains in f.name\n",
        "    ]\n",
        "    logging.info(f\"removing {len(files)} text files\")\n",
        "    for f in files:\n",
        "        os.remove(f)\n",
        "    logging.info(\"done\")\n",
        "\n",
        "\n",
        "def corr(\n",
        "    s: str,\n",
        "    add_space_when_numerics=False,\n",
        "    exceptions=[\"e.g.\", \"i.e.\", \"etc.\", \"cf.\", \"vs.\", \"p.\"],\n",
        ") -> str:\n",
        "    \"\"\"corrects spacing in a string\n",
        "\n",
        "    Args:\n",
        "        s (str): the string to correct\n",
        "        add_space_when_numerics (bool, optional): [add a space when a period is between two numbers, example 5.73]. Defaults to False.\n",
        "        exceptions (list, optional): [do not change these substrings]. Defaults to ['e.g.', 'i.e.', 'etc.', 'cf.', 'vs.', 'p.'].\n",
        "\n",
        "    Returns:\n",
        "        str: the corrected string\n",
        "    \"\"\"\n",
        "    if add_space_when_numerics:\n",
        "        s = re.sub(r\"(\\d)\\.(\\d)\", r\"\\1. \\2\", s)\n",
        "\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = re.sub(r'\\s([?.!\"](?:\\s|$))', r\"\\1\", s)\n",
        "\n",
        "    # fix space before apostrophe\n",
        "    s = re.sub(r\"\\s\\'\", r\"'\", s)\n",
        "    # fix space after apostrophe\n",
        "    s = re.sub(r\"'\\s\", r\"'\", s)\n",
        "    # fix space before comma\n",
        "    s = re.sub(r\"\\s,\", r\",\", s)\n",
        "\n",
        "    for e in exceptions:\n",
        "        expected_sub = re.sub(r\"\\s\", \"\", e)\n",
        "        s = s.replace(expected_sub, e)\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "def fix_punct_spaces(string):\n",
        "    \"\"\"\n",
        "    fix_punct_spaces - replace spaces around punctuation with punctuation. For example, \"hello , there\" -> \"hello, there\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    string : str, required, input string to be corrected\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str, corrected string\n",
        "    \"\"\"\n",
        "\n",
        "    fix_spaces = re.compile(r\"\\s*([?!.,]+(?:\\s+[?!.,]+)*)\\s*\")\n",
        "    string = fix_spaces.sub(lambda x: \"{} \".format(x.group(1).replace(\" \", \"\")), string)\n",
        "    string = string.replace(\" ' \", \"'\")\n",
        "    string = string.replace(' \" ', '\"')\n",
        "    return string.strip()\n",
        "\n",
        "\n",
        "def clean_OCR(ugly_text: str):\n",
        "    \"\"\"\n",
        "    clean_OCR - clean the OCR text files.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ugly_text : str, required, input string to be cleaned\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str, cleaned string\n",
        "    \"\"\"\n",
        "    # Remove all the newlines.\n",
        "    cleaned_text = ugly_text.replace(\"\\n\", \" \")\n",
        "    # Remove all the tabs.\n",
        "    cleaned_text = cleaned_text.replace(\"\\t\", \" \")\n",
        "    # Remove all the double spaces.\n",
        "    cleaned_text = cleaned_text.replace(\"  \", \" \")\n",
        "    # Remove all the spaces at the beginning of the text.\n",
        "    cleaned_text = cleaned_text.lstrip()\n",
        "    # remove all instances of \"- \" and \" - \"\n",
        "    cleaned_text = cleaned_text.replace(\"- \", \"\")\n",
        "    cleaned_text = cleaned_text.replace(\" -\", \"\")\n",
        "    return fix_punct_spaces(cleaned_text)\n",
        "\n",
        "\n",
        "def move2completed(from_dir, filename, new_folder=\"completed\", verbose=False):\n",
        "\n",
        "    # this is the better version\n",
        "    old_filepath = join(from_dir, filename)\n",
        "\n",
        "    new_filedirectory = join(from_dir, new_folder)\n",
        "\n",
        "    if not os.path.isdir(new_filedirectory):\n",
        "        os.mkdir(new_filedirectory)\n",
        "        if verbose:\n",
        "            print(\"created new directory for files at: \\n\", new_filedirectory)\n",
        "    new_filepath = join(new_filedirectory, filename)\n",
        "\n",
        "    try:\n",
        "        shutil.move(old_filepath, new_filepath)\n",
        "        logging.info(\"successfully moved the file {} to */completed.\".format(filename))\n",
        "    except:\n",
        "        logging.info(\n",
        "            \"ERROR! unable to move file to \\n{}. Please investigate\".format(\n",
        "                new_filepath\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "\"\"\"## pdf2text functions\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "custom_replace_list = {\n",
        "    \"t0\": \"to\",\n",
        "    \"'$\": \"'s\",\n",
        "    \",,\": \", \",\n",
        "    \"_ \": \" \",\n",
        "    \" '\": \"'\",\n",
        "}\n",
        "\n",
        "replace_corr_exceptions = {\n",
        "    \"i. e.\": \"i.e.\",\n",
        "    \"e. g.\": \"e.g.\",\n",
        "    \"e. g\": \"e.g.\",\n",
        "    \" ,\": \",\",\n",
        "}\n",
        "\n",
        "\n",
        "spell = SpellChecker()\n",
        "\n",
        "\n",
        "def check_word_spelling(word: str) -> bool:\n",
        "    \"\"\"\n",
        "    check_word_spelling - check the spelling of a word\n",
        "\n",
        "    Args:\n",
        "        word (str): word to check\n",
        "\n",
        "    Returns:\n",
        "        bool: True if word is spelled correctly, False if not\n",
        "    \"\"\"\n",
        "\n",
        "    misspelled = spell.unknown([word])\n",
        "\n",
        "    return len(misspelled) == 0\n",
        "\n",
        "\n",
        "def eval_and_replace(text: str, match_token: str = \"- \") -> str:\n",
        "    \"\"\"\n",
        "    eval_and_replace  - conditionally replace all instances of a substring in a string based on whether the eliminated substring results in a valid word\n",
        "\n",
        "    Args:\n",
        "        text (str): text to evaluate\n",
        "        match_token (str, optional): token to replace. Defaults to \"- \".\n",
        "\n",
        "    Returns:\n",
        "        str:  text with replaced tokens\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        if match_token not in text:\n",
        "            return text\n",
        "        else:\n",
        "            while True:\n",
        "                full_before_text = text.split(match_token, maxsplit=1)[0]\n",
        "                before_text = [\n",
        "                    char for char in full_before_text.split()[-1] if char.isalpha()\n",
        "                ]\n",
        "                before_text = \"\".join(before_text)\n",
        "                full_after_text = text.split(match_token, maxsplit=1)[-1]\n",
        "                after_text = [char for char in full_after_text.split()[0] if char.isalpha()]\n",
        "                after_text = \"\".join(after_text)\n",
        "                full_text = before_text + after_text\n",
        "                if check_word_spelling(full_text):\n",
        "                    text = full_before_text + full_after_text\n",
        "                else:\n",
        "                    text = full_before_text + \" \" + full_after_text\n",
        "                if match_token not in text:\n",
        "                    break\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error spell-checking OCR output, returning default text:\\t{e}\")\n",
        "    return text\n",
        "\n",
        "\n",
        "def cleantxt_ocr(ugly_text, lower=False, lang: str = \"en\") -> str:\n",
        "    \"\"\"\n",
        "    cleantxt_ocr - clean text from OCR\n",
        "\n",
        "    Args:\n",
        "        ugly_text (str): text to clean\n",
        "        lower (bool, optional): _description_. Defaults to False.\n",
        "        lang (str, optional): _description_. Defaults to \"en\".\n",
        "\n",
        "    Returns:\n",
        "        str: cleaned text\n",
        "    \"\"\"\n",
        "    # a wrapper for clean text with options different than default\n",
        "\n",
        "    # https://pypi.org/project/clean-text/\n",
        "    cleaned_text = clean(\n",
        "        ugly_text,\n",
        "        fix_unicode=True,  # fix various unicode errors\n",
        "        to_ascii=True,  # transliterate to closest ASCII representation\n",
        "        lower=lower,  # lowercase text\n",
        "        no_line_breaks=True,  # fully strip line breaks as opposed to only normalizing them\n",
        "        no_urls=True,  # replace all URLs with a special token\n",
        "        no_emails=True,  # replace all email addresses with a special token\n",
        "        no_phone_numbers=False,  # replace all phone numbers with a special token\n",
        "        no_numbers=False,  # replace all numbers with a special token\n",
        "        no_digits=False,  # replace all digits with a special token\n",
        "        no_currency_symbols=False,  # replace all currency symbols with a special token\n",
        "        no_punct=False,  # remove punctuations\n",
        "        replace_with_punct=\"\",  # instead of removing punctuations you may replace them\n",
        "        replace_with_url=\"<URL>\",\n",
        "        replace_with_email=\"<EMAIL>\",\n",
        "        replace_with_phone_number=\"<PHONE>\",\n",
        "        replace_with_number=\"<NUM>\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"<CUR>\",\n",
        "        lang=lang,  # set to 'de' for German special handling\n",
        "    )\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "\n",
        "def format_ocr_out(OCR_data):\n",
        "\n",
        "    if isinstance(OCR_data, list):\n",
        "        text = \" \".join(OCR_data)\n",
        "    else:\n",
        "        text = str(OCR_data)\n",
        "    _clean = cleantxt_ocr(text)\n",
        "    return corr(_clean)\n",
        "\n",
        "\n",
        "def postprocess(text: str) -> str:\n",
        "    \"\"\"to be used after recombining the lines\"\"\"\n",
        "\n",
        "    proc = corr(cleantxt_ocr(text))\n",
        "\n",
        "    for k, v in custom_replace_list.items():\n",
        "        proc = proc.replace(str(k), str(v))\n",
        "\n",
        "    proc = corr(proc)\n",
        "\n",
        "    for k, v in replace_corr_exceptions.items():\n",
        "        proc = proc.replace(str(k), str(v))\n",
        "\n",
        "    return eval_and_replace(proc)\n",
        "\n",
        "\n",
        "def result2text(result, as_text=False) -> str or list:\n",
        "    \"\"\"Convert OCR result to text\"\"\"\n",
        "\n",
        "    full_doc = []\n",
        "    for i, page in enumerate(result.pages, start=1):\n",
        "        text = \"\"\n",
        "        for block in page.blocks:\n",
        "            text += \"\\n\\t\"\n",
        "            for line in block.lines:\n",
        "                for word in line.words:\n",
        "                    # print(dir(word))\n",
        "                    text += word.value + \" \"\n",
        "        full_doc.append(text)\n",
        "\n",
        "    return \"\\n\".join(full_doc) if as_text else full_doc\n",
        "\n",
        "\n",
        "def convert_PDF_to_Text(\n",
        "    PDF_file,\n",
        "    ocr_model=None,\n",
        "    max_pages: int = 20,\n",
        "):\n",
        "\n",
        "    st = time.perf_counter()\n",
        "    PDF_file = Path(PDF_file)\n",
        "    ocr_model = ocr_predictor(pretrained=True) if ocr_model is None else ocr_model\n",
        "    logging.info(f\"starting OCR on {PDF_file.name}\")\n",
        "    doc = DocumentFile.from_pdf(PDF_file)\n",
        "    truncated = False\n",
        "    if len(doc) > max_pages:\n",
        "        logging.warning(\n",
        "            f\"PDF has {len(doc)} pages, which is more than {max_pages}.. truncating\"\n",
        "        )\n",
        "        doc = doc[:max_pages]\n",
        "        truncated = True\n",
        "\n",
        "    # Analyze\n",
        "    logging.info(f\"running OCR on {len(doc)} pages\")\n",
        "    result = ocr_model(doc)\n",
        "    raw_text = result2text(result)\n",
        "    proc_text = [format_ocr_out(r) for r in raw_text]\n",
        "    fin_text = [postprocess(t) for t in proc_text]\n",
        "\n",
        "    ocr_results = \"\\n\\n\".join(fin_text)\n",
        "\n",
        "    fn_rt = time.perf_counter() - st\n",
        "\n",
        "    logging.info(\"OCR complete\")\n",
        "\n",
        "    results_dict = {\n",
        "        \"num_pages\": len(doc),\n",
        "        \"runtime\": round(fn_rt, 2),\n",
        "        \"date\": str(date.today()),\n",
        "        \"converted_text\": ocr_results,\n",
        "        \"truncated\": truncated,\n",
        "        \"length\": len(ocr_results),\n",
        "    }\n",
        "\n",
        "    return results_dict\n",
        "\n",
        "\n",
        "# @title translation functions\n",
        "\n",
        "lt = LibreTranslateAPI(\"https://translate.astian.org/\")\n",
        "\n",
        "\n",
        "def translate_text(text, source_l, target_l=\"en\"):\n",
        "\n",
        "    return str(lt.translate(text, source_l, target_l))\n",
        "\n",
        "\n",
        "def translate_doc(filepath, lang_start, lang_end=\"en\", verbose=False):\n",
        "    \"\"\"translate a document from lang_start to lang_end\n",
        "\n",
        "        {'code': 'en', 'name': 'English'},\n",
        "    {'code': 'fr', 'name': 'French'},\n",
        "    {'code': 'de', 'name': 'German'},\n",
        "    {'code': 'it', 'name': 'Italian'},\"\"\"\n",
        "\n",
        "    src_folder = dirname(filepath)\n",
        "    src_folder = Path(src_folder)\n",
        "    trgt_folder = src_folder / f\"translated_{lang_end}\"\n",
        "    trgt_folder.mkdir(exist_ok=True)\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        foreign_t = f.readlines()\n",
        "    in_name = basename(filepath)\n",
        "    translated_doc = []\n",
        "    for line in tqdm(\n",
        "        foreign_t, total=len(foreign_t), desc=\"translating {}...\".format(in_name[:10])\n",
        "    ):\n",
        "        translated_line = translate_text(line, lang_start, lang_end)\n",
        "        translated_doc.append(translated_line)\n",
        "    t_out_name = \"[To {}]\".format(lang_end) + simple_rename(in_name) + \".txt\"\n",
        "    out_path = join(trgt_folder, t_out_name)\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\", errors=\"ignore\") as f_o:\n",
        "        f_o.writelines(translated_doc)\n",
        "    if verbose:\n",
        "        print(\"finished translating the document! - \", datetime.now())\n",
        "    return out_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "pQ2dx1hTG8__",
        "outputId": "40d71864-073f-4b8f-f96c-f543a627ca7e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Activation' object has no attribute 'get_output_at'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3a39085f96d7>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading OCR model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mocr_model\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mocr_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdet_arch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'db_resnet50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreco_arch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'crnn_vgg16_bn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/doctr/models/zoo.py\u001b[0m in \u001b[0;36mocr_predictor\u001b[0;34m(det_arch, reco_arch, pretrained, pretrained_backbone, assume_straight_pages, preserve_aspect_ratio, symmetric_pad, export_as_straight_boxes, detect_orientation, straighten_pages, detect_language, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mOCR\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[0;32m--> 114\u001b[0;31m     return _predictor(\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mdet_arch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mreco_arch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/doctr/models/zoo.py\u001b[0m in \u001b[0;36m_predictor\u001b[0;34m(det_arch, reco_arch, pretrained, pretrained_backbone, assume_straight_pages, preserve_aspect_ratio, symmetric_pad, det_bs, reco_bs, detect_orientation, straighten_pages, detect_language, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m ) -> OCRPredictor:\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     det_predictor = detection_predictor(\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mdet_arch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/doctr/models/detection/zoo.py\u001b[0m in \u001b[0;36mdetection_predictor\u001b[0;34m(arch, pretrained, assume_straight_pages, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mDetection\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massume_straight_pages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/doctr/models/detection/zoo.py\u001b[0m in \u001b[0;36m_predictor\u001b[0;34m(arch, pretrained, assume_straight_pages, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"unknown architecture '{arch}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         _model = detection.__dict__[arch](\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mpretrained_backbone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pretrained_backbone\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/doctr/models/detection/differentiable_binarization/tensorflow.py\u001b[0m in \u001b[0;36mdb_resnet50\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0mdetection\u001b[0m \u001b[0marchitecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m     return _db_resnet(\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;34m\"db_resnet50\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/doctr/models/detection/differentiable_binarization/tensorflow.py\u001b[0m in \u001b[0;36m_db_resnet\u001b[0;34m(arch, pretrained, backbone_fn, fpn_layers, pretrained_backbone, input_shape, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m# Feature extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     feat_extractor = IntermediateLayerGetter(\n\u001b[0m\u001b[1;32m    297\u001b[0m         backbone_fn(\n\u001b[1;32m    298\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpretrained_backbone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/doctr/models/utils/tensorflow.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, layer_names)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mintermediate_fmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintermediate_fmaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/doctr/models/utils/tensorflow.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mintermediate_fmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintermediate_fmaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Activation' object has no attribute 'get_output_at'"
          ]
        }
      ],
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        ")\n",
        "\n",
        "_here = Path().parent\n",
        "\n",
        "def load_uploaded_file(file_obj, temp_dir: Path = None):\n",
        "    # check if mysterious file object is a list\n",
        "    if isinstance(file_obj, list):\n",
        "        file_obj = file_obj[0]\n",
        "    file_path = Path(file_obj.name)\n",
        "\n",
        "    if temp_dir is None:\n",
        "        _temp_dir = _here / \"temp\"\n",
        "    _temp_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        pdf_bytes_obj = open(file_path, \"rb\").read()\n",
        "        temp_path = temp_dir / file_path.name if temp_dir else file_path\n",
        "        # save to PDF file\n",
        "        with open(temp_path, \"wb\") as f:\n",
        "            f.write(pdf_bytes_obj)\n",
        "        logging.info(f\"Saved uploaded file to {temp_path}\")\n",
        "        return str(temp_path.resolve())\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Trying to load file with path {file_path}, error: {e}\")\n",
        "        print(f\"Trying to load file with path {file_path}, error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def convert_PDF(\n",
        "    pdf_obj,\n",
        "    language: str = \"en\",\n",
        "    max_pages=20,\n",
        "):\n",
        "    \"\"\"\n",
        "    convert_PDF - convert a PDF file to text\n",
        "\n",
        "    Args:\n",
        "        pdf_bytes_obj (bytes): PDF file contents\n",
        "        language (str, optional): Language to use for OCR. Defaults to \"en\".\n",
        "\n",
        "    Returns:\n",
        "        str, the PDF file contents as text\n",
        "    \"\"\"\n",
        "    # clear local text cache\n",
        "    rm_local_text_files()\n",
        "    global ocr_model\n",
        "    st = time.perf_counter()\n",
        "    if isinstance(pdf_obj, list):\n",
        "        pdf_obj = pdf_obj[0]\n",
        "    file_path = Path(pdf_obj.name)\n",
        "    if not file_path.suffix == \".pdf\":\n",
        "        logging.error(f\"File {file_path} is not a PDF file\")\n",
        "\n",
        "        html_error = f\"\"\"\n",
        "        <div style=\"color: red; font-size: 20px; font-weight: bold;\">\n",
        "        File {file_path} is not a PDF file. Please upload a PDF file.\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        return \"File is not a PDF file\", html_error, None\n",
        "\n",
        "    conversion_stats = convert_PDF_to_Text(\n",
        "        file_path,\n",
        "        ocr_model=ocr_model,\n",
        "        max_pages=max_pages,\n",
        "    )\n",
        "    converted_txt = conversion_stats[\"converted_text\"]\n",
        "    num_pages = conversion_stats[\"num_pages\"]\n",
        "    was_truncated = conversion_stats[\"truncated\"]\n",
        "    # if alt_lang: # TODO: fix this\n",
        "\n",
        "    rt = round((time.perf_counter() - st) / 60, 2)\n",
        "    print(f\"Runtime: {rt} minutes\")\n",
        "    html = \"\"\n",
        "    if was_truncated:\n",
        "        html += f\"<p>WARNING - PDF was truncated to {max_pages} pages</p>\"\n",
        "    html += f\"<p>Runtime: {rt} minutes on CPU for {num_pages} pages</p>\"\n",
        "\n",
        "    _output_name = f\"RESULT_{file_path.stem}_OCR.txt\"\n",
        "    with open(_output_name, \"w\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        f.write(converted_txt)\n",
        "\n",
        "    return converted_txt, html, _output_name\n",
        "\n",
        "\n",
        "\n",
        "logging.info(\"Starting app\")\n",
        "\n",
        "use_GPU = torch.cuda.is_available()\n",
        "print(f\"Using GPU status: {use_GPU}\")\n",
        "logging.info(\"Loading OCR model\")\n",
        "\n",
        "ocr_model = ocr_predictor(\n",
        "    \"db_resnet50\",\n",
        "    \"crnn_mobilenet_v3_large\",\n",
        "    pretrained=True,\n",
        "    assume_straight_pages=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6lOYsifr_WH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NidmXX88ruUh"
      },
      "outputs": [],
      "source": [
        "def process_ocr_text(ocr_text):\n",
        "    questions = []\n",
        "    option_counter = 1\n",
        "    current_question = {}\n",
        "    for line in ocr_text.split(\"\\n\"):\n",
        "        print(line)\n",
        "        if re.match(r'^\\d+\\. ', line):\n",
        "            if current_question:\n",
        "                questions.append(current_question)  # Append the previous question before creating a new one\n",
        "            current_question = {\"q\": line.split(' ', 1)[1].strip()}  # Create a new question dictionary\n",
        "            option_counter = 1\n",
        "        elif line.strip().startswith(\"(\") and \")\" in line:\n",
        "            option, text = line.strip().split(\")\", 1)\n",
        "            current_question[\"o\" + str(option_counter)] = text.strip()\n",
        "            option_counter += 1\n",
        "\n",
        "    if current_question:\n",
        "        questions.append(current_question)  # Append the last question if there is any\n",
        "    return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RimEa_hjyyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc1b58e-3d5e-4f23-957b-6b92610e789e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://07b7-34-126-110-84.ngrok-free.app\" -> \"http://127.0.0.1:8070\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:8070\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FileStorage: 'test.pdf' ('application/pdf')>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [24/Jul/2024 06:26:42] \"\u001b[35m\u001b[1mPOST /OCR HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/\n",
            "<FileStorage: 'test.pdf' ('application/pdf')>\n",
            "Runtime: 0.18 minutes\n",
            "Fluid Mechanics JEE Mains 2019 Chapter wise Question Bank JEE Mains 2019 Chapter wise Question Bank Fluid Mechanics  Questions Q1 8 April Morning The top of a water tank is open to air and its water lavel is maintained. It is giving out 0.74m water per minute through a circular opening of2 cm radius in its wall. The depth ofthe centre ofthe opening from theievel of water Q5 4 5 A wooden block floating in a bucket of water has ofits volume submerged. When certain amount of an oil poured into the bucket, it is found that the block is just under the oil surface with half of its volume under water and half in oil. The density of oil relative to that of water is: in the tank is close to: (I) 6.0m (3) 9.6m Q2 (2) 4.8m (4) 2.9m 9 Jan Evening (1) 0.5 Q6 (2) 0.8 (3 0.6 (4) 0.7 9 April Evening Water flows into a large tank with flat bottom at the rate of 10-4 m3 s-(1) Water is also leaking out of a hole of area 1 cm2 at its bottom. If the height of the water in the tank-remains steady, then this height is: A cubical block of side 0.5 m floats on water with 30% of its volume under water. What is the maximum weight that can be put on the block without fully submerging it under water? [Take, density ofwater LE 10 kg/m'] (1) 46.3 kg (2) 87.5 kg (3) 65.4 kg (4) 30.1 kg ey 5.1 cm (3) 4 cm Q3 (2) 7 cm (4) 9 cm 10 Jan Morning 10 April Evening Q7 A long cylindrical vessel is half filled with a liquid. When the vessel is rotated about its Own vertical axis, the liquid rises up near the wall. Ifthe radius ofvessel is 5 cm and its rotational speed is 2 rotations per second, then the difference inthe heights between the centre and the sides, in cm, will be : A submarine experiences a pressure of 5.05x10 Pa at depth of d, in a sea. When it goes further to a depth of dy it experiences a pressure of 8.08x10% Pa. Then d, dis approximately (density of water=10'kg/m and acceleration due to gravity 1 10 ms?): (1) 300 m (2) 400 m (3) 600 m (4) 500 m (1) 2.0 (3) 0.4 Q4 (2) 0.1 (4) 1.2 12Jan Evening 10 April Evening Q8 Water from a pipe is coming at a rate of 100 liters per minute. If the radius of the pipe is 5 cm, the Reynolds number for the flow is of the order of: (density of water 1000 kg/m?, coefficient of viscosity of water = 1 mPa S) (1) 103 (2) 104 (3) 102 (4) 106 To download more free study materials, visit <URL>\n",
            "\n",
            "Fluid Mechanics JEE Mains 2019 Chapter wise Question Bank Water from a tap emerges vertically downwards with an initial speed of 1.0 ms-'. The cross-sectional area of the tap is 1041 m?. Assume that the pressure is constant throughout the stream of water and that the flow is streamlined. The cross-sectional area of the stream, 0,15 m below the tap would be : [Take g 1 10 ms-?) (1) 2x10S m? (3) 5x104 m? Q9 (2) 5x10-Sm? (4) 1x10-5 m? 10 April Evening A solid sphere, of radius R acquires a terminal velocity Vi when falling (due to gravity) through a viscous fluid having a coefficient of viscosity n. The sphere is broken into 27 identical solid spheres. Ife each of these spheres acquires a terminal velocity, V2 when falling through the same fluid, the ratio (v,/v,) equals: (1) 9 (2) 1/27 (3) 1/9 (4) 27 12 April Evening mathongo To download more free study materials, visit <URL>\n",
            "\n",
            "Fluid Mechanics JEE Mains 2019 Chapter wise Question Bank JEE Mains 2019 Chapter wise Question Bank Fluid Mechanics  Answers Q1 Q3 (2) Here, volume tric flowrate 0.74 rv-(rx4x10')x/2gh 60 74x100  2gh 240r 740x740 a 2gh= = 24x24x10 74x74 sh= 2x24x24 (1) Using v2 = u? + 2gy [-.u=0at(0,0)] [.v=ox] I 0 a (0,0) v2 =2gy 2gh 740 24r 10 X 4.8m i.e., The depth of the centre of the opening from the level ofwater in the tank is close to 4 8 m @ X (2x2m)'x(0.05) a  2g 2cm 12Jan Evening 20 9 Jan Evening  A  e  Q2 (1) Q4 : (2) Rate of flow of water (P) = 100 lit/min 100x10-3 5 x10-3m 60 3 Velocity of flow of'water (v) V 5x10-3 A 3xx(5x10-3)? 10 2 15r 3r m/s 11 0.2 m/s : Reynold number (Nw) i1 (10x10-2)x 2 x1000 Order ofNr 11 104 Qin h * Qout Dvp n 2x10* Since height of water column is constant therefore, water inflow rate (Qin = water outflow rate Qin 11 10-4 m's-1 Qout = Au 1 10-4xV2gh : 104=104x /20xh 3r 1 8 April Morning Q5 : h m 5 cm 20 10 Jan Morning To download more free study materials, visit <URL>\n",
            "\n",
            "Fluid Mechanics 4V (3) Mg = pog 5 M 4po or T 5 4p00 or P= 5 JEE Mains 2019 Chapter wise Question Bank (2) Using Bernoullie's equation 5) + pgh 2 = 2gh D  V2 + 2gh Equation of continuity AjY, E La 2V, (1 cm?) (1 m/s) i A, U 10 2 When block floats fully in water and oil, then 15 100 Mg = Fh +Fbz (pVg = Poil? 3 or Poil 1M pw 11 0.6po 5 2 pog 10 April Evening 9 April Evening Q9 Q6 4 4 (1) 27 X T3 = Tr3 3 R or 3 Terminal V OC 2 velocity, V2 5 2 or V, 2'1 or i1 9. V2 (2) When a body floats then the weight of the body = upthrust 30 100 :.(50) X X (1) X g 11 M cube8 Let m mass should be placed, then (50)3 X (1) X g 1 (M, cube + m)g ...(i) ..(ii) Subtracting equation (i) from equation (ii), we get a mg 1 (50) X g 0.3) = 125 X 0.7 X 103 g R/ /3 m 1 87.5 kg 10 April Evening Q7 (1) P,=I Po+ pgd, + pgd, AP   pgAd 3.03 x 106 = 103 X 10 X Ad Ad LE 300 m 12 April Evening 10 April Evening Q8 To download more free study materials, visit <URL>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [24/Jul/2024 06:27:01] \"\u001b[35m\u001b[1mPOST /OCR HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReplicateError Details:\n",
            "title: Unauthenticated\n",
            "status: 401\n",
            "detail: You did not pass a valid authentication token\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "from io import BytesIO\n",
        "from flask_cors import CORS\n",
        "import replicate\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "port = 8070\n",
        "\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n",
        "\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/OCR', methods=['POST'])\n",
        "def get_OCR():\n",
        "    try:\n",
        "        uploaded_file = request.files['pdf']\n",
        "\n",
        "        print(uploaded_file)\n",
        "\n",
        "        if uploaded_file.mimetype == 'application/pdf':\n",
        "        # pdf_link = \"./test.pdf\"\n",
        "        # with open(pdf_link, 'rb') as f:\n",
        "        #     pdf_data = f.read()\n",
        "\n",
        "          filename = \"temp.pdf\"\n",
        "          with open(filename, 'wb') as f:\n",
        "              f.write(uploaded_file.read())\n",
        "          pdf_obj = open(filename, 'rb')\n",
        "        else:\n",
        "            return jsonify({'error': 'Invalid file format. Please upload a PDF file.'}), 400\n",
        "\n",
        "        # define pdf bytes as None\n",
        "        pdf_obj = _here / \"temp.pdf\"\n",
        "        pdf_obj = str(pdf_obj.resolve())\n",
        "        pdf_obj = open(pdf_obj, \"rb\")\n",
        "        _temp_dir = _here / \"temp\"\n",
        "        _temp_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        OCR_text, out_placeholder, text_file = convert_PDF(pdf_obj)\n",
        "\n",
        "        print(OCR_text)\n",
        "\n",
        "\n",
        "        # Your base prompt and OCR_text\n",
        "        base_prompt = \"\"\"Please format the OCR data provided below into a multiple-choice question paper. Each question should be followed by options labeled A, B, C, and D. Maintain the format as follows:\n",
        "\n",
        "1. [Question]\n",
        "   (A) [Option A]\n",
        "   (B) [Option B]\n",
        "   (C) [Option C]\n",
        "   (D) [Option D]\n",
        "\n",
        "2. [Question]\n",
        "   (A) ...\n",
        "   ...\n",
        "\n",
        "[OCR Data: Insert OCR data here]\n",
        "\n",
        "Please disregard any marketing content and do not assume additional information. Your task is solely to format the questions and options properly. There's no need to provide answers to these questions.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        # Define a variable to store the processed OCR text\n",
        "        processed_text =  \"\"\n",
        "\n",
        "        # Example replicate event loop\n",
        "        for event in replicate.stream(\n",
        "            \"mistralai/mixtral-8x7b-instruct-v0.1\",\n",
        "            input={\n",
        "                \"top_k\": 50,\n",
        "                \"top_p\": 0.9,\n",
        "                \"prompt\": base_prompt + OCR_text,\n",
        "                \"temperature\": 0.8,\n",
        "                \"max_new_tokens\": 2048,\n",
        "                \"prompt_template\": \"<s>[INST] {prompt} [/INST] \",\n",
        "                \"presence_penalty\": 0,\n",
        "                \"frequency_penalty\": 0\n",
        "            },\n",
        "        ):\n",
        "            # Store the processed OCR text\n",
        "            processed_text += str(event)\n",
        "\n",
        "\n",
        "\n",
        "        json_data = process_ocr_text(processed_text)\n",
        "        return jsonify(json_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=\"8070\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw6Brk2nKkOU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATEQv9vFSVeC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}